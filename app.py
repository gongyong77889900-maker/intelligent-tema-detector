import streamlit as st
import pandas as pd
import numpy as np
import io
import re
import logging
from collections import defaultdict
from datetime import datetime
from itertools import combinations
import warnings
import traceback

# é…ç½®æ—¥å¿—å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('MultiAccountWashTrade')

# Streamlité¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

class Config:
    """é…ç½®å‚æ•°ç±»"""
    def __init__(self):
        self.min_amount = 10
        self.amount_similarity_threshold = 0.9
        self.min_continuous_periods = 3
        self.max_accounts_in_group = 5
        self.supported_file_types = ['.xlsx', '.xls', '.csv']
        
        # åˆ—åæ˜ å°„é…ç½®
        self.column_mappings = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢']
        }
        
        # ä¿®æ­£ï¼šæ ¹æ®è´¦æˆ·æ€»æŠ•æ³¨æœŸæ•°è®¾ç½®ä¸åŒçš„å¯¹åˆ·æœŸæ•°é˜ˆå€¼
        self.period_thresholds = {
            'low_activity': 10,        # ä½æ´»è·ƒåº¦è´¦æˆ·é˜ˆå€¼ï¼ˆæ€»æŠ•æ³¨æœŸæ•°â‰¤10ï¼‰
            'medium_activity_low': 11,  # ä¸­æ´»è·ƒåº¦ä¸‹é™ï¼ˆæ€»æŠ•æ³¨æœŸæ•°11-200ï¼‰
            'medium_activity_high': 200, # ä¸­æ´»è·ƒåº¦ä¸Šé™
            'min_periods_low': 3,       # ä½æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_medium': 5,    # ä¸­æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_high': 8       # é«˜æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
        }
        
        # æ‰©å±•ï¼šå¢åŠ é¾™è™æ–¹å‘æ¨¡å¼
        self.direction_patterns = {
            'å°': ['ä¸¤é¢-å°', 'å’Œå€¼-å°', 'å°', 'small', 'xia'],
            'å¤§': ['ä¸¤é¢-å¤§', 'å’Œå€¼-å¤§', 'å¤§', 'big', 'da'], 
            'å•': ['ä¸¤é¢-å•', 'å’Œå€¼-å•', 'å•', 'odd', 'dan'],
            'åŒ': ['ä¸¤é¢-åŒ', 'å’Œå€¼-åŒ', 'åŒ', 'even', 'shuang'],
            'é¾™': ['é¾™', 'long', 'é¾', 'dragon'],
            'è™': ['è™', 'hu', 'tiger']
        }
        
        # æ‰©å±•ï¼šå¢åŠ é¾™è™å¯¹ç«‹ç»„
        self.opposite_groups = [{'å¤§', 'å°'}, {'å•', 'åŒ'}, {'é¾™', 'è™'}]

class WashTradeDetector:
    def __init__(self, config=None):
        self.config = config or Config()
        self.data_processed = False
        self.df_valid = None
        self.export_data = []
        # ä¿®æ­£ï¼šæŒ‰å½©ç§å­˜å‚¨è´¦æˆ·æ€»æŠ•æ³¨æœŸæ•°ç»Ÿè®¡
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        self.column_mapping_used = {}
        self.performance_stats = {}
    
    def upload_and_process(self, uploaded_file):
        """ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶"""
        try:
            if uploaded_file is None:
                st.error("âŒ æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
                return None, None
            
            filename = uploaded_file.name
            logger.info(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {filename}")
            
            if not any(filename.endswith(ext) for ext in self.config.supported_file_types):
                st.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
                return None, None
            
            if filename.endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='utf-8')
            else:
                df = pd.read_excel(uploaded_file)
            
            logger.info(f"åŸå§‹æ•°æ®ç»´åº¦: {df.shape}")
            
            return df, filename
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            return None, None
    
    def map_columns(self, df):
        """æ˜ å°„åˆ—ååˆ°æ ‡å‡†æ ¼å¼"""
        reverse_mapping = {}
        for standard_col, possible_cols in self.config.column_mappings.items():
            for col in possible_cols:
                reverse_mapping[col] = standard_col
        
        column_mapping = {}
        used_columns = set()
        
        for df_col in df.columns:
            df_col_clean = str(df_col).strip()
            
            if df_col_clean in reverse_mapping:
                standard_col = reverse_mapping[df_col_clean]
                if standard_col not in used_columns:
                    column_mapping[df_col] = standard_col
                    used_columns.add(standard_col)
                continue
            
            for possible_col in reverse_mapping.keys():
                if possible_col in df_col_clean:
                    standard_col = reverse_mapping[possible_col]
                    if standard_col not in used_columns:
                        column_mapping[df_col] = standard_col
                        used_columns.add(standard_col)
                    break
        
        if column_mapping:
            df_renamed = df.rename(columns=column_mapping)
            self.column_mapping_used = column_mapping
            return df_renamed
        else:
            return df
    
    def check_required_columns(self, df):
        """æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨"""
        required_cols = ['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å†…å®¹', 'é‡‘é¢']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            st.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
            st.write("å¯ç”¨çš„åˆ—:", df.columns.tolist())
            return False
        
        if 'å½©ç§' not in df.columns:
            df['å½©ç§'] = 'æœªçŸ¥å½©ç§'
        
        return True
    
    def parse_column_data(self, df):
        """è§£æåˆ—ç»“æ„æ•°æ®"""
        try:
            df_mapped = self.map_columns(df)
            
            if not self.check_required_columns(df_mapped):
                return pd.DataFrame()
            
            df_clean = df_mapped[['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å†…å®¹', 'é‡‘é¢', 'å½©ç§']].copy()
            df_clean = df_clean.dropna(subset=['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å†…å®¹', 'é‡‘é¢'])
            
            for col in ['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å†…å®¹', 'å½©ç§']:
                if col in df_clean.columns:
                    df_clean[col] = df_clean[col].astype(str).str.strip()
            
            # å…³é”®ä¿®æ­£ï¼šåœ¨è¿‡æ»¤å‰è®¡ç®—æ€»æŠ•æ³¨æœŸæ•°
            self.calculate_account_total_periods_by_lottery(df_clean)
            
            df_clean['æŠ•æ³¨é‡‘é¢'] = df_clean['é‡‘é¢'].apply(lambda x: self.extract_bet_amount_safe(x))
            df_clean['æŠ•æ³¨æ–¹å‘'] = df_clean['å†…å®¹'].apply(lambda x: self.extract_direction_from_content(x))
            
            df_valid = df_clean[
                (df_clean['æŠ•æ³¨æ–¹å‘'] != '') & 
                (df_clean['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
            ].copy()
            
            if len(df_valid) == 0:
                st.error("âŒ è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆè®°å½•")
                return pd.DataFrame()
            
            with st.expander("ğŸ“Š æ•°æ®æ¦‚è§ˆ", expanded=False):
                st.write(f"æ€»è®°å½•æ•°: {len(df_clean)}")
                st.write(f"æœ‰æ•ˆè®°å½•æ•°: {len(df_valid)}")
                st.write(f"å”¯ä¸€æœŸå·æ•°: {df_valid['æœŸå·'].nunique()}")
                st.write(f"å”¯ä¸€è´¦æˆ·æ•°: {df_valid['ä¼šå‘˜è´¦å·'].nunique()}")
                
                if len(df_valid) > 0:
                    lottery_stats = df_valid['å½©ç§'].value_counts()
                    st.write(f"å½©ç§åˆ†å¸ƒ: {dict(lottery_stats)}")
                    
                    # æ˜¾ç¤ºæŠ•æ³¨æ–¹å‘åˆ†å¸ƒ
                    direction_stats = df_valid['æŠ•æ³¨æ–¹å‘'].value_counts()
                    st.write(f"æŠ•æ³¨æ–¹å‘åˆ†å¸ƒ: {dict(direction_stats)}")
            
            self.data_processed = True
            self.df_valid = df_valid
            return df_valid
            
        except Exception as e:
            logger.error(f"æ•°æ®è§£æå¤±è´¥: {str(e)}")
            st.error(f"æ•°æ®è§£æå¤±è´¥: {str(e)}")
            st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return pd.DataFrame()
    
    def extract_bet_amount_safe(self, amount_text):
        """å®‰å…¨æå–æŠ•æ³¨é‡‘é¢"""
        try:
            if pd.isna(amount_text):
                return 0
            
            text = str(amount_text).strip()
            
            try:
                cleaned_text = text.replace(',', '').replace('ï¼Œ', '').replace(' ', '')
                if re.match(r'^-?\d+(\.\d+)?$', cleaned_text):
                    amount = float(cleaned_text)
                    if amount >= self.config.min_amount:
                        return amount
            except:
                pass
            
            patterns = [
                r'æŠ•æ³¨[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'ä¸‹æ³¨[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'é‡‘é¢[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'æ€»é¢[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'(\d+[,ï¼Œ]?\d*\.?\d*)\s*å…ƒ',
                r'ï¿¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'Â¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'[\$ï¿¥Â¥]?\s*(\d+[,ï¼Œ]?\d*\.?\d+)',
                r'(\d+[,ï¼Œ]?\d*\.?\d+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text)
                if match:
                    amount_str = match.group(1).replace(',', '').replace('ï¼Œ', '').replace(' ', '')
                    try:
                        amount = float(amount_str)
                        if amount >= self.config.min_amount:
                            return amount
                    except:
                        continue
            
            numbers = re.findall(r'\d+\.?\d*', text)
            if numbers:
                try:
                    amount = float(numbers[0])
                    if amount >= self.config.min_amount:
                        return amount
                except:
                    pass
            
            return 0
            
        except Exception as e:
            logger.warning(f"é‡‘é¢æå–å¤±è´¥: {amount_text}, é”™è¯¯: {e}")
            return 0
    
    def extract_direction_from_content(self, content):
        """ä»å†…å®¹åˆ—æå–æŠ•æ³¨æ–¹å‘"""
        try:
            if pd.isna(content):
                return ""
            
            content_str = str(content).strip().lower()
            
            for direction, patterns in self.config.direction_patterns.items():
                for pattern in patterns:
                    if pattern.lower() in content_str:
                        return direction
            
            return ""
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return ""
    
    def calculate_account_total_periods_by_lottery(self, df):
        """ä¿®æ­£ï¼šæŒ‰å½©ç§è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°ç»Ÿè®¡ï¼ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼‰"""
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        
        for lottery in df['å½©ç§'].unique():
            df_lottery = df[df['å½©ç§'] == lottery]
            
            # è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°ï¼ˆå”¯ä¸€æœŸå·æ•°ï¼‰
            period_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·')['æœŸå·'].nunique().to_dict()
            self.account_total_periods_by_lottery[lottery] = period_counts
            
            # è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„è®°å½•æ•°
            record_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·').size().to_dict()
            self.account_record_stats_by_lottery[lottery] = record_counts
    
    def detect_all_wash_trades(self):
        """æ£€æµ‹æ‰€æœ‰ç±»å‹çš„å¯¹åˆ·äº¤æ˜“"""
        if not self.data_processed or self.df_valid is None or len(self.df_valid) == 0:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ç”¨äºæ£€æµ‹")
            return []
        
        self.performance_stats = {
            'start_time': datetime.now(),
            'total_records': len(self.df_valid),
            'total_periods': self.df_valid['æœŸå·'].nunique(),
            'total_accounts': self.df_valid['ä¼šå‘˜è´¦å·'].nunique()
        }
        
        df_filtered = self.exclude_multi_direction_accounts(self.df_valid)
        
        if len(df_filtered) == 0:
            st.error("âŒ è¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®")
            return []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_patterns = []
        total_steps = self.config.max_accounts_in_group - 1
        
        for account_count in range(2, self.config.max_accounts_in_group + 1):
            status_text.text(f"ğŸ” æ£€æµ‹{account_count}ä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼...")
            patterns = self.detect_n_account_patterns_optimized(df_filtered, account_count)
            all_patterns.extend(patterns)
            
            progress = (account_count - 1) / total_steps
            progress_bar.progress(progress)
        
        progress_bar.progress(1.0)
        status_text.text("âœ… æ£€æµ‹å®Œæˆ")
        
        self.performance_stats['end_time'] = datetime.now()
        self.performance_stats['detection_time'] = (
            self.performance_stats['end_time'] - self.performance_stats['start_time']
        ).total_seconds()
        self.performance_stats['total_patterns'] = len(all_patterns)
        
        self.display_performance_stats()
        
        return all_patterns
    
    def detect_n_account_patterns_optimized(self, df_filtered, n_accounts):
        """ä¼˜åŒ–ç‰ˆçš„Nä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼æ£€æµ‹"""
        wash_records = []
        
        period_groups = df_filtered.groupby(['æœŸå·', 'å½©ç§'])
        
        valid_direction_combinations = self._get_valid_direction_combinations(n_accounts)
        
        batch_size = 100
        period_keys = list(period_groups.groups.keys())
        
        for i in range(0, len(period_keys), batch_size):
            batch_keys = period_keys[i:i+batch_size]
            
            for period_key in batch_keys:
                period_data = period_groups.get_group(period_key)
                period_accounts = period_data['ä¼šå‘˜è´¦å·'].unique()
                
                if len(period_accounts) < n_accounts:
                    continue
                
                batch_patterns = self._detect_combinations_for_period(
                    period_data, period_accounts, n_accounts, valid_direction_combinations
                )
                wash_records.extend(batch_patterns)
        
        return self.find_continuous_patterns_optimized(wash_records)
    
    def _get_valid_direction_combinations(self, n_accounts):
        """è·å–æœ‰æ•ˆçš„æ–¹å‘ç»„åˆ"""
        valid_combinations = []
        
        for opposites in self.config.opposite_groups:
            dir1, dir2 = list(opposites)
            
            for i in range(1, n_accounts):
                j = n_accounts - i
                valid_combinations.append({
                    'directions': [dir1] * i + [dir2] * j,
                    'dir1_count': i,
                    'dir2_count': j,
                    'opposite_type': f"{dir1}-{dir2}"
                })
        
        return valid_combinations
    
    def _detect_combinations_for_period(self, period_data, period_accounts, n_accounts, valid_combinations):
        """ä¸ºå•ä¸ªæœŸå·æ£€æµ‹ç»„åˆ"""
        patterns = []
        
        account_info = {}
        for _, row in period_data.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            account_info[account] = {
                'direction': row['æŠ•æ³¨æ–¹å‘'],
                'amount': row['æŠ•æ³¨é‡‘é¢']
            }
        
        for account_group in combinations(period_accounts, n_accounts):
            for combo in valid_combinations:
                target_directions = combo['directions']
                
                actual_directions = [account_info[acc]['direction'] for acc in account_group]
                if sorted(actual_directions) != sorted(target_directions):
                    continue
                
                dir1_total = 0
                dir2_total = 0
                
                for account, target_dir in zip(account_group, target_directions):
                    actual_dir = account_info[account]['direction']
                    amount = account_info[account]['amount']
                    
                    if actual_dir == combo['opposite_type'].split('-')[0]:
                        dir1_total += amount
                    else:
                        dir2_total += amount
                
                if dir1_total == 0 or dir2_total == 0:
                    continue
                
                similarity = min(dir1_total, dir2_total) / max(dir1_total, dir2_total)
                
                if similarity >= self.config.amount_similarity_threshold:
                    amount_group = [account_info[acc]['amount'] for acc in account_group]
                    
                    record = {
                        'æœŸå·': period_data['æœŸå·'].iloc[0],
                        'å½©ç§': period_data['å½©ç§'].iloc[0],
                        'è´¦æˆ·ç»„': list(account_group),
                        'æ–¹å‘ç»„': actual_directions,
                        'é‡‘é¢ç»„': amount_group,
                        'æ€»é‡‘é¢': dir1_total + dir2_total,
                        'ç›¸ä¼¼åº¦': similarity,
                        'è´¦æˆ·æ•°é‡': n_accounts,
                        'æ¨¡å¼': f"{combo['opposite_type'].split('-')[0]}({combo['dir1_count']}ä¸ª) vs {combo['opposite_type'].split('-')[1]}({combo['dir2_count']}ä¸ª)",
                        'å¯¹ç«‹ç±»å‹': combo['opposite_type']
                    }
                    
                    patterns.append(record)
        
        return patterns
    
    def find_continuous_patterns_optimized(self, wash_records):
        """ä¼˜åŒ–ç‰ˆçš„è¿ç»­å¯¹åˆ·æ¨¡å¼æ£€æµ‹"""
        if not wash_records:
            return []
        
        account_group_patterns = defaultdict(list)
        for record in wash_records:
            account_group_key = (tuple(sorted(record['è´¦æˆ·ç»„'])), record['å½©ç§'])
            account_group_patterns[account_group_key].append(record)
        
        continuous_patterns = []
        
        for (account_group, lottery), records in account_group_patterns.items():
            sorted_records = sorted(records, key=lambda x: x['æœŸå·'])
            
            # ä¿®æ­£ï¼šæ ¹æ®è´¦æˆ·ç»„çš„æ€»æŠ•æ³¨æœŸæ•°ç¡®å®šæœ€å°å¯¹åˆ·æœŸæ•°è¦æ±‚
            required_min_periods = self.get_required_min_periods(account_group, lottery)
            
            if len(sorted_records) >= required_min_periods:
                total_investment = sum(r['æ€»é‡‘é¢'] for r in sorted_records)
                similarities = [r['ç›¸ä¼¼åº¦'] for r in sorted_records]
                avg_similarity = np.mean(similarities) if similarities else 0
                
                opposite_type_counts = defaultdict(int)
                for record in sorted_records:
                    opposite_type_counts[record['å¯¹ç«‹ç±»å‹']] += 1
                
                pattern_count = defaultdict(int)
                for record in sorted_records:
                    pattern_count[record['æ¨¡å¼']] += 1
                
                main_opposite_type = max(opposite_type_counts.items(), key=lambda x: x[1])[0]
                
                # ä¿®æ­£ï¼šæ˜¾ç¤ºæ¯ä¸ªè´¦æˆ·çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
                account_stats_info = []
                total_periods_stats = self.account_total_periods_by_lottery.get(lottery, {})
                record_stats = self.account_record_stats_by_lottery.get(lottery, {})
                
                for account in account_group:
                    total_periods = total_periods_stats.get(account, 0)
                    records_count = record_stats.get(account, 0)
                    account_stats_info.append(f"{account}({total_periods}æœŸ/{records_count}è®°å½•)")
                
                activity_level = self.get_account_group_activity_level(account_group, lottery)
                
                continuous_patterns.append({
                    'è´¦æˆ·ç»„': list(account_group),
                    'å½©ç§': lottery,
                    'è´¦æˆ·æ•°é‡': len(account_group),
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': main_opposite_type,
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': dict(opposite_type_counts),
                    'å¯¹åˆ·æœŸæ•°': len(sorted_records),  # å®é™…å¯¹åˆ·æœŸæ•°
                    'æ€»æŠ•æ³¨é‡‘é¢': total_investment,
                    'å¹³å‡ç›¸ä¼¼åº¦': avg_similarity,
                    'æ¨¡å¼åˆ†å¸ƒ': dict(pattern_count),
                    'è¯¦ç»†è®°å½•': sorted_records,
                    'è´¦æˆ·æ´»è·ƒåº¦': activity_level,
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': account_stats_info,  # ä¿®æ­£ï¼šæ˜¾ç¤ºæ¯ä¸ªè´¦æˆ·çš„ç»Ÿè®¡ä¿¡æ¯
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': required_min_periods
                })
        
        return continuous_patterns
    
    def exclude_multi_direction_accounts(self, df_valid):
        """æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨"""
        multi_direction_mask = (
            df_valid.groupby(['æœŸå·', 'ä¼šå‘˜è´¦å·'])['æŠ•æ³¨æ–¹å‘']
            .transform('nunique') > 1
        )
        
        df_filtered = df_valid[~multi_direction_mask].copy()
        
        return df_filtered
    
    def get_account_group_activity_level(self, account_group, lottery):
        """ä¿®æ­£ï¼šæ ¹æ®è´¦æˆ·ç»„åœ¨ç‰¹å®šå½©ç§çš„æ€»æŠ•æ³¨æœŸæ•°è·å–æ´»è·ƒåº¦æ°´å¹³"""
        if lottery not in self.account_total_periods_by_lottery:
            return 'unknown'
        
        total_periods_stats = self.account_total_periods_by_lottery[lottery]
        
        # è®¡ç®—è´¦æˆ·ç»„ä¸­åœ¨æŒ‡å®šå½©ç§çš„æœ€å°æ€»æŠ•æ³¨æœŸæ•°ï¼ˆç”¨äºæ´»è·ƒåº¦åˆ¤æ–­ï¼‰
        min_total_periods = min(total_periods_stats.get(account, 0) for account in account_group)
        
        # æŒ‰ç…§æ‚¨è¦æ±‚çš„æ´»è·ƒåº¦é˜ˆå€¼è®¾ç½®
        if min_total_periods <= self.config.period_thresholds['low_activity']:
            return 'low'        # æ€»æŠ•æ³¨æœŸæ•°â‰¤10
        elif min_total_periods <= self.config.period_thresholds['medium_activity_high']:
            return 'medium'     # æ€»æŠ•æ³¨æœŸæ•°11-200
        else:
            return 'high'       # æ€»æŠ•æ³¨æœŸæ•°â‰¥201
    
    def get_required_min_periods(self, account_group, lottery):
        """ä¿®æ­£ï¼šæ ¹æ®è´¦æˆ·ç»„çš„æ€»æŠ•æ³¨æœŸæ•°æ´»è·ƒåº¦è·å–æ‰€éœ€çš„æœ€å°å¯¹åˆ·æœŸæ•°"""
        activity_level = self.get_account_group_activity_level(account_group, lottery)
        
        if activity_level == 'low':
            return self.config.period_thresholds['min_periods_low']    # 3æœŸ
        elif activity_level == 'medium':
            return self.config.period_thresholds['min_periods_medium'] # 5æœŸ
        else:
            return self.config.period_thresholds['min_periods_high']   # 8æœŸ
    
    def display_performance_stats(self):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        if not self.performance_stats:
            return
        
        with st.expander("ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡", expanded=False):
            st.write(f"**æ•°æ®å¤„ç†ç»Ÿè®¡:**")
            st.write(f"- æ€»è®°å½•æ•°: {self.performance_stats['total_records']:,}")
            st.write(f"- æ€»æœŸå·æ•°: {self.performance_stats['total_periods']:,}")
            st.write(f"- æ€»è´¦æˆ·æ•°: {self.performance_stats['total_accounts']:,}")
            
            if 'detection_time' in self.performance_stats:
                st.write(f"**æ£€æµ‹æ€§èƒ½:**")
                st.write(f"- æ£€æµ‹æ—¶é—´: {self.performance_stats['detection_time']:.2f} ç§’")
                st.write(f"- å‘ç°æ¨¡å¼: {self.performance_stats['total_patterns']} ä¸ª")
                
                if self.performance_stats['detection_time'] > 0:
                    records_per_second = self.performance_stats['total_records'] / self.performance_stats['detection_time']
                    st.write(f"- å¤„ç†é€Ÿåº¦: {records_per_second:.1f} æ¡è®°å½•/ç§’")
    
    def display_detailed_results(self, patterns):
        """æ˜¾ç¤ºè¯¦ç»†æ£€æµ‹ç»“æœ - ä»¥å½©ç§ä¸ºç‹¬ç«‹åŒ…è£…ï¼Œé»˜è®¤å±•å¼€"""
        st.write("\n" + "="*60)
        st.write("ğŸ¯ å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç»“æœ")
        st.write("="*60)
        
        if not patterns:
            st.error("âŒ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„è¿ç»­å¯¹åˆ·æ¨¡å¼")
            return
        
        patterns_by_lottery = defaultdict(list)
        for pattern in patterns:
            patterns_by_lottery[pattern['å½©ç§']].append(pattern)
        
        for lottery, lottery_patterns in patterns_by_lottery.items():
            # ä½¿ç”¨expanderåŒ…è£…æ¯ä¸ªå½©ç§ï¼Œé»˜è®¤å±•å¼€
            with st.expander(f"ğŸ² å½©ç§ï¼š{lottery}ï¼ˆå‘ç°{len(lottery_patterns)}ç»„ï¼‰", expanded=True):
                for i, pattern in enumerate(lottery_patterns, 1):
                    # å¯¹åˆ·ç»„ä¿¡æ¯
                    st.markdown(f"**å¯¹åˆ·ç»„ {i}:** {' â†” '.join(pattern['è´¦æˆ·ç»„'])}")
                    
                    # æ´»è·ƒåº¦ä¿¡æ¯
                    activity_icon = "ğŸŸ¢" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'low' else "ğŸŸ¡" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'medium' else "ğŸ”´"
                    st.markdown(f"**æ´»è·ƒåº¦:** {activity_icon} {pattern['è´¦æˆ·æ´»è·ƒåº¦']} | **å½©ç§:** {pattern['å½©ç§']} | **ä¸»è¦ç±»å‹:** {pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']}")
                    
                    # è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
                    st.markdown(f"**è´¦æˆ·åœ¨è¯¥å½©ç§æŠ•æ³¨æœŸæ•°/è®°å½•æ•°:** {', '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯'])}")
                    
                    # å¯¹åˆ·æœŸæ•°
                    st.markdown(f"**å¯¹åˆ·æœŸæ•°:** {pattern['å¯¹åˆ·æœŸæ•°']}æœŸ (è¦æ±‚â‰¥{pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°']}æœŸ)")
                    
                    # é‡‘é¢ä¿¡æ¯
                    st.markdown(f"**æ€»é‡‘é¢:** {pattern['æ€»æŠ•æ³¨é‡‘é¢']:.2f}å…ƒ | **å¹³å‡åŒ¹é…:** {pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}")
                    
                    # è¯¦ç»†è®°å½• - ç›´æ¥å±•å¼€æ˜¾ç¤º
                    st.markdown("**è¯¦ç»†è®°å½•:**")
                    for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                        account_directions = []
                        for account, direction, amount in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„']):
                            account_directions.append(f"{account}({direction}:{amount})")
                        
                        st.markdown(f"{j}. **æœŸå·:** {record['æœŸå·']} | **æ¨¡å¼:** {record['æ¨¡å¼']} | **æ–¹å‘:** {' â†” '.join(account_directions)} | **åŒ¹é…åº¦:** {record['ç›¸ä¼¼åº¦']:.2%}")
                    
                    # å¯¹åˆ·ç»„ä¹‹é—´çš„åˆ†éš”çº¿
                    if i < len(lottery_patterns):
                        st.markdown("---")
        
        self.display_summary_statistics(patterns)
    
    def display_summary_statistics(self, patterns):
        """æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡"""
        if not patterns:
            return
            
        st.write(f"\n{'='*60}")
        st.write("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        st.write(f"{'='*60}")
        
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_wash_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        account_count_stats = defaultdict(int)
        for pattern in patterns:
            account_count_stats[pattern['è´¦æˆ·æ•°é‡']] += 1
        
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            lottery_stats[pattern['å½©ç§']] += 1
        
        # æ´»è·ƒåº¦åˆ†å¸ƒ
        activity_stats = defaultdict(int)
        for pattern in patterns:
            activity_stats[pattern['è´¦æˆ·æ´»è·ƒåº¦']] += 1
        
        # å¯¹ç«‹ç±»å‹åˆ†å¸ƒ
        opposite_type_stats = defaultdict(int)
        for pattern in patterns:
            for opposite_type, count in pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ'].items():
                opposite_type_stats[opposite_type] += count
        
        st.write(f"**ğŸ¯ æ£€æµ‹ç»“æœæ±‡æ€»:**")
        st.write(f"- å¯¹åˆ·ç»„æ•°: {total_groups} ç»„")
        st.write(f"- æ¶‰åŠè´¦æˆ·: {total_accounts} ä¸ª")
        st.write(f"- æ€»å¯¹åˆ·æœŸæ•°: {total_wash_periods} æœŸ")
        st.write(f"- æ€»æ¶‰åŠé‡‘é¢: {total_amount:.2f} å…ƒ")
        
        st.write(f"**ğŸ‘¥ æŒ‰è´¦æˆ·æ•°é‡åˆ†å¸ƒ:**")
        for account_count, count in sorted(account_count_stats.items()):
            st.write(f"- {account_count}ä¸ªè´¦æˆ·ç»„: {count} ç»„")
        
        st.write(f"**ğŸ² æŒ‰å½©ç§åˆ†å¸ƒ:**")
        for lottery, count in lottery_stats.items():
            st.write(f"- {lottery}: {count} ç»„")
            
        st.write(f"**ğŸ“ˆ æŒ‰æ´»è·ƒåº¦åˆ†å¸ƒ:**")
        for activity, count in activity_stats.items():
            st.write(f"- {activity}æ´»è·ƒåº¦: {count} ç»„")
            
        st.write(f"**ğŸ¯ æŒ‰å¯¹ç«‹ç±»å‹åˆ†å¸ƒ:**")
        for opposite_type, count in opposite_type_stats.items():
            st.write(f"- {opposite_type}: {count} æœŸå¯¹åˆ·")
    
    def export_to_excel(self, patterns, filename):
        """å¯¼å‡ºæ£€æµ‹ç»“æœåˆ°Excelæ–‡ä»¶"""
        if not patterns:
            st.error("âŒ æ²¡æœ‰å¯¹åˆ·æ•°æ®å¯å¯¼å‡º")
            return None, None
        
        export_data = []
        
        for group_idx, pattern in enumerate(patterns, 1):
            for record_idx, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                account_directions = []
                for account, direction, amount in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„']):
                    account_directions.append(f"{account}({direction}:{amount})")
                
                export_data.append({
                    'å¯¹åˆ·ç»„ç¼–å·': group_idx,
                    'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                    'å½©ç§': pattern['å½©ç§'],
                    'è´¦æˆ·æ•°é‡': pattern['è´¦æˆ·æ•°é‡'],
                    'è´¦æˆ·æ´»è·ƒåº¦': pattern['è´¦æˆ·æ´»è·ƒåº¦'],
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': ', '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯']),
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°'],
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': pattern['ä¸»è¦å¯¹ç«‹ç±»å‹'],
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': str(pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ']),
                    'å¯¹åˆ·æœŸæ•°': pattern['å¯¹åˆ·æœŸæ•°'],
                    'æ€»æŠ•æ³¨é‡‘é¢': pattern['æ€»æŠ•æ³¨é‡‘é¢'],
                    'å¹³å‡ç›¸ä¼¼åº¦': f"{pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}",
                    'æ¨¡å¼åˆ†å¸ƒ': str(pattern['æ¨¡å¼åˆ†å¸ƒ']),
                    'æœŸå·': record['æœŸå·'],
                    'å¯¹ç«‹ç±»å‹': record['å¯¹ç«‹ç±»å‹'],
                    'æ¨¡å¼': record['æ¨¡å¼'],
                    'é‡‘é¢': record['æ€»é‡‘é¢'],
                    'åŒ¹é…åº¦': f"{record['ç›¸ä¼¼åº¦']:.2%}",
                    'è´¦æˆ·æ–¹å‘': ' | '.join(account_directions)
                })
        
        df_export = pd.DataFrame(export_data)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        export_filename = f"å¯¹åˆ·æ£€æµ‹æŠ¥å‘Š_æ™ºèƒ½ç‰ˆ_{timestamp}.xlsx"
        
        try:
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df_export.to_excel(writer, sheet_name='è¯¦ç»†è®°å½•', index=False)
                
                summary_data = []
                for group_idx, pattern in enumerate(patterns, 1):
                    summary_data.append({
                        'å¯¹åˆ·ç»„ç¼–å·': group_idx,
                        'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                        'å½©ç§': pattern['å½©ç§'],
                        'è´¦æˆ·æ•°é‡': pattern['è´¦æˆ·æ•°é‡'],
                        'è´¦æˆ·æ´»è·ƒåº¦': pattern['è´¦æˆ·æ´»è·ƒåº¦'],
                        'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': ', '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯']),
                        'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°'],
                        'ä¸»è¦å¯¹ç«‹ç±»å‹': pattern['ä¸»è¦å¯¹ç«‹ç±»å‹'],
                        'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': str(pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ']),
                        'å¯¹åˆ·æœŸæ•°': pattern['å¯¹åˆ·æœŸæ•°'],
                        'æ€»æŠ•æ³¨é‡‘é¢': pattern['æ€»æŠ•æ³¨é‡‘é¢'],
                        'å¹³å‡ç›¸ä¼¼åº¦': f"{pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}",
                        'æ¨¡å¼åˆ†å¸ƒ': str(pattern['æ¨¡å¼åˆ†å¸ƒ'])
                    })
                
                df_summary = pd.DataFrame(summary_data)
                df_summary.to_excel(writer, sheet_name='å¯¹åˆ·ç»„æ±‡æ€»', index=False)
            
            output.seek(0)
            st.success(f"âœ… ExcelæŠ¥å‘Šå·²ç”Ÿæˆ: {export_filename}")
            
            return output, export_filename
            
        except Exception as e:
            st.error(f"âŒ å¯¼å‡ºExcelå¤±è´¥: {str(e)}")
            return None, None

# ç‰¹ç å®Œç¾è¦†ç›–åˆ†æç³»ç»Ÿçš„å‡½æ•°
def extract_bet_amount_perfect_coverage(amount_text):
    """ä»å¤æ‚æ–‡æœ¬ä¸­æå–æŠ•æ³¨é‡‘é¢ - ç‰¹ç åˆ†æä¸“ç”¨"""
    try:
        if pd.isna(amount_text):
            return 0
        
        text = str(amount_text).strip()
        
        # å…ˆå°è¯•ç›´æ¥è½¬æ¢
        try:
            cleaned_text = text.replace(',', '').replace('ï¼Œ', '')
            amount = float(cleaned_text)
            if amount >= 0:
                return amount
        except:
            pass
        
        # å¤šç§é‡‘é¢æå–æ¨¡å¼
        patterns = [
            r'æŠ•æ³¨[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
            r'æŠ•æ³¨\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
            r'é‡‘é¢[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
            r'(\d+[,ï¼Œ]?\d*\.?\d*)\s*å…ƒ',
            r'ï¿¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
            r'Â¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
            r'(\d+[,ï¼Œ]?\d*\.?\d*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                amount_str = match.group(1).replace(',', '').replace('ï¼Œ', '')
                try:
                    amount = float(amount_str)
                    if amount >= 0:
                        return amount
                except:
                    continue
        
        return 0
    except Exception as e:
        st.warning(f"é‡‘é¢æå–å¤±è´¥: {amount_text}, é”™è¯¯: {e}")
        return 0

def find_correct_columns_perfect_coverage(df):
    """æ‰¾åˆ°æ­£ç¡®çš„åˆ— - ç‰¹ç åˆ†æä¸“ç”¨"""
    column_mapping = {}
    used_standard_cols = set()
    
    for col in df.columns:
        col_str = str(col).lower().strip()
        
        # ä¼šå‘˜è´¦å·åˆ—
        if 'ä¼šå‘˜è´¦å·' not in used_standard_cols and any(keyword in col_str for keyword in ['ä¼šå‘˜', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·']):
            column_mapping[col] = 'ä¼šå‘˜è´¦å·'
            used_standard_cols.add('ä¼šå‘˜è´¦å·')
        
        # æœŸå·åˆ—
        elif 'æœŸå·' not in used_standard_cols and any(keyword in col_str for keyword in ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ']):
            column_mapping[col] = 'æœŸå·'
            used_standard_cols.add('æœŸå·')
        
        # å½©ç§åˆ—
        elif 'å½©ç§' not in used_standard_cols and any(keyword in col_str for keyword in ['å½©ç§', 'å½©ç¥¨', 'æ¸¸æˆç±»å‹']):
            column_mapping[col] = 'å½©ç§'
            used_standard_cols.add('å½©ç§')
        
        # ç©æ³•åˆ†ç±»åˆ—
        elif 'ç©æ³•åˆ†ç±»' not in used_standard_cols and any(keyword in col_str for keyword in ['ç©æ³•åˆ†ç±»', 'ç©æ³•', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹']):
            column_mapping[col] = 'ç©æ³•åˆ†ç±»'
            used_standard_cols.add('ç©æ³•åˆ†ç±»')
        
        # å†…å®¹åˆ—
        elif 'å†…å®¹' not in used_standard_cols and any(keyword in col_str for keyword in ['å†…å®¹', 'æŠ•æ³¨', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹']):
            column_mapping[col] = 'å†…å®¹'
            used_standard_cols.add('å†…å®¹')
        
        # é‡‘é¢åˆ—
        elif 'é‡‘é¢' not in used_standard_cols and any(keyword in col_str for keyword in ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢']):
            column_mapping[col] = 'é‡‘é¢'
            used_standard_cols.add('é‡‘é¢')
    
    return column_mapping

def extract_numbers_from_content(content):
    """ä»å†…å®¹ä¸­æå–æ‰€æœ‰1-49çš„æ•°å­—"""
    numbers = []
    content_str = str(content)
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰æ•°å­—
    number_matches = re.findall(r'\d+', content_str)
    for match in number_matches:
        num = int(match)
        if 1 <= num <= 49:
            numbers.append(num)
    
    return list(set(numbers))  # å»é‡

def format_numbers_display(numbers):
    """æ ¼å¼åŒ–æ•°å­—æ˜¾ç¤ºï¼Œç¡®ä¿ä¸¤ä½æ•°æ˜¾ç¤º"""
    formatted = []
    for num in sorted(numbers):
        formatted.append(f"{num:02d}")
    return ", ".join(formatted)

def calculate_similarity(avgs):
    """è®¡ç®—é‡‘é¢åŒ¹é…åº¦"""
    if not avgs or max(avgs) == 0:
        return 0
    return (min(avgs) / max(avgs)) * 100

def get_similarity_indicator(similarity):
    """è·å–ç›¸ä¼¼åº¦é¢œè‰²æŒ‡ç¤ºç¬¦"""
    if similarity >= 90:
        return "ğŸŸ¢"
    elif similarity >= 80:
        return "ğŸŸ¡"
    elif similarity >= 70:
        return "ğŸŸ "
    else:
        return "ğŸ”´"

def run_perfect_coverage_analysis(df):
    """è¿è¡Œç‰¹ç å®Œç¾è¦†ç›–åˆ†æ"""
    st.header("ğŸ¯ ç‰¹ç å®Œç¾è¦†ç›–åˆ†æ")
    
    # å®šä¹‰éœ€è¦åˆ†æçš„8ç§å…­åˆå½©å½©ç§
    target_lotteries = [
        'æ–°æ¾³é—¨å…­åˆå½©', 'æ¾³é—¨å…­åˆå½©', 'é¦™æ¸¯å…­åˆå½©', 'ä¸€åˆ†å…­åˆå½©',
        'äº”åˆ†å…­åˆå½©', 'ä¸‰åˆ†å…­åˆå½©', 'é¦™æ¸¯â‘¥åˆå½©', 'åˆ†åˆ†å…­åˆå½©'
    ]
    
    # ç­›é€‰ç›®æ ‡å½©ç§å’Œç‰¹ç ç©æ³•
    df_target = df[
        (df['å½©ç§'].isin(target_lotteries)) & 
        (df['ç©æ³•åˆ†ç±»'] == 'ç‰¹ç ')
    ]
    
    st.write(f"âœ… ç‰¹ç ç©æ³•æ•°æ®è¡Œæ•°: {len(df_target):,}")
    
    if len(df_target) == 0:
        st.warning("âŒ æ²¡æœ‰æ‰¾åˆ°ç‰¹ç ç©æ³•æ•°æ®")
        return
    
    # æŒ‰æœŸæ•°å’Œå½©ç§åˆ†ç»„åˆ†æ
    grouped = df_target.groupby(['æœŸå·', 'å½©ç§'])
    st.write(f"ğŸ“… å…±å‘ç° {len(grouped):,} ä¸ªæœŸæ•°+å½©ç§ç»„åˆ")
    
    all_period_results = {}
    valid_periods = 0
    
    # è¿›åº¦æ¡
    progress_bar = st.progress(0)
    total_groups = len(grouped)
    
    for i, ((period, lottery), group) in enumerate(grouped):
        if len(group) < 10:  # æ•°æ®é‡å¤ªå°‘çš„è·³è¿‡
            continue
        
        result = analyze_period_lottery_combination(group, period, lottery)
        if result:
            all_period_results[(period, lottery)] = result
            valid_periods += 1
        
        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.progress((i + 1) / total_groups)
    
    st.success(f"âœ… åˆ†æå®Œæˆï¼å…±åˆ†æ {valid_periods} ä¸ªæœ‰æ•ˆæœŸæ•°")
    
    # æ˜¾ç¤ºæ‰€æœ‰æœŸæ•°çš„å®Œæ•´ç»„åˆ
    st.header("ğŸ“Š æ‰€æœ‰æœŸæ•°çš„å®Œæ•´ç»„åˆå±•ç¤º")
    
    for (period, lottery), result in all_period_results.items():
        all_results = result['all_results']
        total_combinations = result['total_combinations']
        
        if total_combinations > 0:
            with st.expander(f"ğŸ“… æœŸå·[{period}] - å½©ç§[{lottery}] (å…±{total_combinations}ä¸ªå®Œç¾ç»„åˆ)", expanded=True):
                # æ˜¾ç¤º2è´¦æˆ·ç»„åˆ
                if all_results[2]:
                    st.subheader(f"ğŸ‘¥ 2ä¸ªè´¦å·ç»„åˆ (å…±{len(all_results[2])}ç»„)")
                    for i, result_data in enumerate(all_results[2], 1):
                        st.markdown(f"**ğŸ¯ ç»„åˆ {i}**")
                        accounts = result_data['accounts']
                        st.write(f"ğŸ”¥ è´¦æˆ·ç»„: {accounts[0]} â†” {accounts[1]}")
                        st.write(f"ğŸ“Š æ€»æ•°å­—æ•°: {result_data['total_digits']}")
                        st.write(f"ğŸ’° æ€»æŠ•æ³¨é‡‘é¢: {result_data['total_amount']:,.2f} å…ƒ")
                        st.write(f"ğŸ’¯ å¹³å‡é‡‘é¢åŒ¹é…: {result_data['similarity']:.2f}% {result_data['similarity_indicator']}")
                        
                        for account in accounts:
                            amount_info = result_data['individual_amounts'][account]
                            avg_info = result_data['individual_avg_per_number'][account]
                            st.write(f"   **{account}:** {len(result_data['bet_contents'][account].split(', '))}ä¸ªæ•°å­— | æ€»æŠ•æ³¨: {amount_info:,.2f}å…ƒ | å¹³å‡æ¯å·: {avg_info:,.2f}å…ƒ")
                            st.write(f"   æŠ•æ³¨å†…å®¹: {result_data['bet_contents'][account]}")
                        
                        st.markdown("---")
                
                # æ˜¾ç¤º3è´¦æˆ·ç»„åˆ
                if all_results[3]:
                    st.subheader(f"ğŸ‘¥ 3ä¸ªè´¦å·ç»„åˆ (å…±{len(all_results[3])}ç»„)")
                    for i, result_data in enumerate(all_results[3], 1):
                        st.markdown(f"**ğŸ¯ ç»„åˆ {i}**")
                        accounts = result_data['accounts']
                        st.write(f"ğŸ”¥ è´¦æˆ·ç»„: {accounts[0]} â†” {accounts[1]} â†” {accounts[2]}")
                        st.write(f"ğŸ“Š æ€»æ•°å­—æ•°: {result_data['total_digits']}")
                        st.write(f"ğŸ’° æ€»æŠ•æ³¨é‡‘é¢: {result_data['total_amount']:,.2f} å…ƒ")
                        st.write(f"ğŸ’¯ å¹³å‡é‡‘é¢åŒ¹é…: {result_data['similarity']:.2f}% {result_data['similarity_indicator']}")
                        
                        for account in accounts:
                            amount_info = result_data['individual_amounts'][account]
                            avg_info = result_data['individual_avg_per_number'][account]
                            st.write(f"   **{account}:** {len(result_data['bet_contents'][account].split(', '))}ä¸ªæ•°å­— | æ€»æŠ•æ³¨: {amount_info:,.2f}å…ƒ | å¹³å‡æ¯å·: {avg_info:,.2f}å…ƒ")
                            st.write(f"   æŠ•æ³¨å†…å®¹: {result_data['bet_contents'][account]}")
                        
                        st.markdown("---")

def analyze_period_lottery_combination(df_period_lottery, period, lottery):
    """åˆ†æç‰¹å®šæœŸæ•°å’Œå½©ç§çš„ç»„åˆ"""
    st.info(f"ğŸ“Š å¤„ç†: æœŸå·[{period}] - å½©ç§[{lottery}] - æ•°æ®é‡: {len(df_period_lottery):,}è¡Œ")
    
    has_amount_column = 'é‡‘é¢' in df_period_lottery.columns
    if has_amount_column:
        df_period_lottery['æŠ•æ³¨é‡‘é¢'] = df_period_lottery['é‡‘é¢'].apply(extract_bet_amount_perfect_coverage)
        period_amount = df_period_lottery['æŠ•æ³¨é‡‘é¢'].sum()
        st.write(f"ğŸ’° æœ¬æœŸæ€»æŠ•æ³¨é¢: {period_amount:,.2f} å…ƒ")
    
    # æŒ‰è´¦æˆ·æå–æ‰€æœ‰ç‰¹ç æ•°å­—å’Œé‡‘é¢ç»Ÿè®¡
    account_numbers = {}
    account_amount_stats = {}
    account_bet_contents = {}

    for account in df_period_lottery['ä¼šå‘˜è´¦å·'].unique():
        account_data = df_period_lottery[df_period_lottery['ä¼šå‘˜è´¦å·'] == account]
        
        # æå–è¯¥è´¦æˆ·ä¸‹æ‰€æœ‰ç‰¹ç æ•°å­—
        all_numbers = set()
        total_amount = 0
        bet_count = 0
        
        for _, row in account_data.iterrows():
            numbers = extract_numbers_from_content(row['å†…å®¹'])
            all_numbers.update(numbers)
            
            if has_amount_column:
                total_amount += row['æŠ•æ³¨é‡‘é¢']
                bet_count += 1
        
        if all_numbers:
            account_numbers[account] = sorted(all_numbers)
            account_bet_contents[account] = format_numbers_display(all_numbers)
            number_count = len(all_numbers)
            account_amount_stats[account] = {
                'number_count': number_count,
                'total_amount': total_amount,
                'bet_count': bet_count,
                'avg_amount_per_bet': total_amount / bet_count if bet_count > 0 else 0,
                'avg_amount_per_number': total_amount / number_count if number_count > 0 else 0
            }

    # æ’é™¤æŠ•æ³¨æ€»æ•°é‡â‰¤11çš„è´¦æˆ·
    filtered_account_numbers = {}
    filtered_account_amount_stats = {}
    filtered_account_bet_contents = {}

    for account, numbers in account_numbers.items():
        num_count = len(numbers)
        if num_count > 11:
            filtered_account_numbers[account] = numbers
            filtered_account_amount_stats[account] = account_amount_stats[account]
            filtered_account_bet_contents[account] = account_bet_contents[account]

    st.write(f"ğŸ‘¥ æœ‰æ•ˆè´¦æˆ·: {len(filtered_account_numbers):,}ä¸ª")

    if len(filtered_account_numbers) < 2:
        st.warning("âŒ æœ‰æ•ˆè´¦æˆ·ä¸è¶³2ä¸ªï¼Œæ— æ³•è¿›è¡Œç»„åˆåˆ†æ")
        return None

    # è¿™é‡Œç®€åŒ–äº†ç»„åˆæœç´¢é€»è¾‘ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦å®Œæ•´å®ç°
    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªç©ºç»“æœ
    return {
        'period': period,
        'lottery': lottery,
        'total_accounts': len(account_numbers),
        'filtered_accounts': len(filtered_account_numbers),
        'total_combinations': 0,
        'best_result': None,
        'all_results': {2: [], 3: [], 4: []}
    }

def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¯ æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    # ä¾§è¾¹æ é…ç½®
    st.sidebar.header("âš™ï¸ æ£€æµ‹å‚æ•°é…ç½®")
    
    min_amount = st.sidebar.number_input("æœ€å°æŠ•æ³¨é‡‘é¢", value=10, min_value=1, help="ä½äºæ­¤é‡‘é¢çš„è®°å½•å°†è¢«è¿‡æ»¤")
    similarity_threshold = st.sidebar.slider("é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼", 0.8, 1.0, 0.9, 0.01, help="å¯¹ç«‹æ–¹å‘é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼")
    max_accounts = st.sidebar.slider("æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°", 2, 8, 5, help="æ£€æµ‹çš„æœ€å¤§è´¦æˆ·ç»„åˆæ•°é‡")
    
    # æ´»è·ƒåº¦é˜ˆå€¼é…ç½® - ä¿®æ­£ç‰ˆ
    st.sidebar.subheader("ğŸ“Š æ´»è·ƒåº¦é˜ˆå€¼é…ç½®ï¼ˆåŸºäºæ€»æŠ•æ³¨æœŸæ•°ï¼‰")
    st.sidebar.markdown("**ä½æ´»è·ƒåº¦:** æ€»æŠ•æ³¨æœŸæ•°â‰¤10æœŸ")
    st.sidebar.markdown("**ä¸­æ´»è·ƒåº¦:** æ€»æŠ•æ³¨æœŸæ•°11-200æœŸ")  
    st.sidebar.markdown("**é«˜æ´»è·ƒåº¦:** æ€»æŠ•æ³¨æœŸæ•°â‰¥201æœŸ")
    
    min_periods_low = st.sidebar.number_input("ä½æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=3, min_value=1, 
                                            help="æ€»æŠ•æ³¨æœŸæ•°â‰¤10çš„è´¦æˆ·ï¼Œè¦æ±‚â‰¥3æœŸè¿ç»­å¯¹åˆ·")
    min_periods_medium = st.sidebar.number_input("ä¸­æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=5, min_value=1,
                                               help="æ€»æŠ•æ³¨æœŸæ•°11-200çš„è´¦æˆ·ï¼Œè¦æ±‚â‰¥5æœŸè¿ç»­å¯¹åˆ·")
    min_periods_high = st.sidebar.number_input("é«˜æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=8, min_value=1,
                                             help="æ€»æŠ•æ³¨æœŸæ•°â‰¥201çš„è´¦æˆ·ï¼Œè¦æ±‚â‰¥8æœŸè¿ç»­å¯¹åˆ·")
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.file_uploader(
        "è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶ (æ”¯æŒ .xlsx, .xls, .csv)", 
        type=['xlsx', 'xls', 'csv'],
        help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—ï¼šä¼šå‘˜è´¦å·ã€æœŸå·ã€å†…å®¹ã€é‡‘é¢"
    )
    
    # ç‰¹ç åˆ†æå¼€å…³
    st.sidebar.header("ğŸ”§ é«˜çº§åŠŸèƒ½")
    enable_perfect_coverage = st.sidebar.checkbox("å¯ç”¨ç‰¹ç å®Œç¾è¦†ç›–åˆ†æ", value=False, 
                                                help="å¯ç”¨å…­åˆå½©ç‰¹ç å®Œç¾è¦†ç›–åˆ†æåŠŸèƒ½")
    
    if uploaded_file is not None:
        try:
            # æ›´æ–°é…ç½®å‚æ•°
            config = Config()
            config.min_amount = min_amount
            config.amount_similarity_threshold = similarity_threshold
            config.max_accounts_in_group = max_accounts
            config.period_thresholds = {
                'low_activity': 10,  # æŒ‰ç…§æ‚¨è¦æ±‚çš„é˜ˆå€¼
                'medium_activity_low': 11,  
                'medium_activity_high': 200, 
                'min_periods_low': min_periods_low,
                'min_periods_medium': min_periods_medium,
                'min_periods_high': min_periods_high
            }
            
            detector = WashTradeDetector(config)
            
            st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            
            with st.spinner("ğŸ”„ æ­£åœ¨è§£ææ•°æ®..."):
                df, filename = detector.upload_and_process(uploaded_file)
                if df is not None:
                    df_valid = detector.parse_column_data(df)
                    
                    if len(df_valid) > 0:
                        st.success("âœ… æ•°æ®è§£æå®Œæˆ")
                        
                        with st.expander("ğŸ“Š æ•°æ®æ¦‚è§ˆ", expanded=False):
                            st.write(f"æœ‰æ•ˆè®°å½•æ•°: {len(df_valid):,}")
                            st.write(f"å”¯ä¸€æœŸå·æ•°: {df_valid['æœŸå·'].nunique():,}")
                            st.write(f"å”¯ä¸€è´¦æˆ·æ•°: {df_valid['ä¼šå‘˜è´¦å·'].nunique():,}")
                        
                        # è‡ªåŠ¨å¼€å§‹æ£€æµ‹
                        st.info("ğŸš€ è‡ªåŠ¨å¼€å§‹æ£€æµ‹å¯¹åˆ·äº¤æ˜“...")
                        with st.spinner("ğŸ” æ­£åœ¨æ£€æµ‹å¯¹åˆ·äº¤æ˜“..."):
                            patterns = detector.detect_all_wash_trades()
                        
                        if patterns:
                            st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {len(patterns)} ä¸ªå¯¹åˆ·ç»„")
                            
                            detector.display_detailed_results(patterns)
                            
                            excel_output, export_filename = detector.export_to_excel(patterns, filename)
                            
                            if excel_output is not None:
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½æ£€æµ‹æŠ¥å‘Š",
                                    data=excel_output,
                                    file_name=export_filename,
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                        else:
                            st.warning("âš ï¸ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„å¯¹åˆ·è¡Œä¸º")
                        
                        # ç‰¹ç å®Œç¾è¦†ç›–åˆ†æï¼ˆå¯é€‰ï¼‰
                        if enable_perfect_coverage:
                            # é‡æ–°è¯»å–åŸå§‹æ•°æ®è¿›è¡Œç‰¹ç åˆ†æ
                            df_original = pd.read_excel(uploaded_file)
                            column_mapping = find_correct_columns_perfect_coverage(df_original)
                            if column_mapping:
                                df_original = df_original.rename(columns=column_mapping)
                            
                            # æ£€æŸ¥å¿…è¦åˆ—
                            required_cols = ['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•åˆ†ç±»', 'å†…å®¹']
                            if all(col in df_original.columns for col in required_cols):
                                run_perfect_coverage_analysis(df_original)
                            else:
                                st.error("âŒ ç‰¹ç åˆ†æç¼ºå°‘å¿…è¦åˆ—ï¼Œè¯·ç¡®ä¿æ–‡ä»¶åŒ…å«ï¼šä¼šå‘˜è´¦å·ã€æœŸå·ã€å½©ç§ã€ç©æ³•åˆ†ç±»ã€å†…å®¹")
                    else:
                        st.error("âŒ æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
            
        except Exception as e:
            st.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
            st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜ï¼ˆæ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿï¼‰"):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½è¯´æ˜

        **ğŸ¯ å¯¹åˆ·æ£€æµ‹é€»è¾‘ï¼š**
        - **æ€»æŠ•æ³¨æœŸæ•°**ï¼šè´¦æˆ·åœ¨ç‰¹å®šå½©ç§ä¸­çš„æ‰€æœ‰æœŸå·æŠ•æ³¨æ¬¡æ•°
        - **å¯¹åˆ·æœŸæ•°**ï¼šè´¦æˆ·ç»„å®é™…å‘ç”Ÿå¯¹åˆ·è¡Œä¸ºçš„æœŸæ•°
        - æ ¹æ®**æ€»æŠ•æ³¨æœŸæ•°**åˆ¤å®šè´¦æˆ·æ´»è·ƒåº¦ï¼Œè®¾ç½®ä¸åŒçš„**å¯¹åˆ·æœŸæ•°**é˜ˆå€¼

        **ğŸ“Š æ´»è·ƒåº¦åˆ¤å®šï¼š**
        - **ä½æ´»è·ƒåº¦è´¦æˆ·**ï¼šæ€»æŠ•æ³¨æœŸæ•° â‰¤ 10æœŸ â†’ è¦æ±‚ â‰¥ 3æœŸè¿ç»­å¯¹åˆ·
        - **ä¸­æ´»è·ƒåº¦è´¦æˆ·**ï¼šæ€»æŠ•æ³¨æœŸæ•° 11-200æœŸ â†’ è¦æ±‚ â‰¥ 5æœŸè¿ç»­å¯¹åˆ·  
        - **é«˜æ´»è·ƒåº¦è´¦æˆ·**ï¼šæ€»æŠ•æ³¨æœŸæ•° â‰¥ 201æœŸ â†’ è¦æ±‚ â‰¥ 8æœŸè¿ç»­å¯¹åˆ·

        **ğŸ¯ å¯¹åˆ·æ£€æµ‹è§„åˆ™ï¼š**
        - æ£€æµ‹2-5ä¸ªè´¦æˆ·ä¹‹é—´çš„å¯¹åˆ·è¡Œä¸º
        - **æ”¯æŒçš„å¯¹ç«‹æŠ•æ³¨ç±»å‹ï¼š**
          - å¤§ vs å°
          - å• vs åŒ  
          - é¾™ vs è™
        - é‡‘é¢åŒ¹é…åº¦ â‰¥ 90%
        - æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨

        **ğŸ² ç‰¹ç å®Œç¾è¦†ç›–åˆ†æï¼š**
        - åœ¨ä¾§è¾¹æ å‹¾é€‰"å¯ç”¨ç‰¹ç å®Œç¾è¦†ç›–åˆ†æ"å³å¯ä½¿ç”¨
        - åˆ†æå…­åˆå½©ç‰¹ç ç©æ³•çš„å®Œç¾æ•°å­—è¦†ç›–ç»„åˆ
        - æ”¯æŒ2-4ä¸ªè´¦æˆ·çš„ç»„åˆåˆ†æ
        - è¦æ±‚ç»„åˆæ•°å­—è¦†ç›–1-49æ‰€æœ‰å·ç ä¸”æ— é‡å¤

        **ğŸ“ æ•°æ®æ ¼å¼è¦æ±‚ï¼š**
        - å¿…é¡»åŒ…å«ï¼šä¼šå‘˜è´¦å·ã€æœŸå·ã€å†…å®¹ã€é‡‘é¢
        - å¯é€‰åŒ…å«ï¼šå½©ç§ï¼ˆå¦‚æ— åˆ™è‡ªåŠ¨æ·»åŠ é»˜è®¤å€¼ï¼‰
        - æ”¯æŒè‡ªåŠ¨åˆ—åæ˜ å°„
        """)

if __name__ == "__main__":
    main()
